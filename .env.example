# =====================================
# Flow Cut - 環境変数設定ファイル
# =====================================
#
# セットアップ手順:
# 1. このファイルを .env にコピー: cp .env.example .env
# 2. 各APIキーを取得して設定
# 3. 使用するモデルを選択（デフォルト値を変更可能）
#

# =====================================
# OpenAI 設定
# =====================================
# APIキー取得: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# 使用するモデル（2025年1月時点の推奨）
# - gpt-4o-mini: 低コスト・高速（推奨）
# - gpt-4o: 高精度・複雑なタスク向け
OPENAI_MODEL=gpt-4o-mini

# =====================================
# Google Gemini 設定
# =====================================
# APIキー取得: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# 使用するモデル（2025年11月時点の推奨）
# - gemini-3-pro-preview: 高精度（デフォルト/Pass1, Pass2）
# - gemini-2.5-flash: コスト最適（Pass3デフォルト）
# - gemini-1.5-flash: 旧デフォルト（高速・低コスト）
GOOGLE_MODEL=gemini-3-pro-preview

# パスごとのモデルを自由指定（プロバイダー不問。openai/gpt-4o なども可）
# 未設定なら上記デフォルトが使われます。
LLM_PASS1_MODEL=gemini-3-pro-preview
LLM_PASS2_MODEL=gemini-3-pro-preview
LLM_PASS3_MODEL=gemini-2.5-flash

# =====================================
# Anthropic Claude 設定
# =====================================
# APIキー取得: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# 使用するモデル（2025年1月時点の推奨）
# - claude-3-5-haiku-20241022: 高速・低コスト
# - claude-3-5-sonnet-20241022: バランス型（推奨）
# - claude-3-5-opus-20240229: 最高精度（高コスト）
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# APIエンドポイント（通常は変更不要）
ANTHROPIC_API_BASE=https://api.anthropic.com/v1

# =====================================
# LLM プロバイダー選択（デフォルト）
# =====================================
# コマンドライン実行時に --llm オプションで上書き可能
# 選択肢: openai, google, anthropic
DEFAULT_LLM_PROVIDER=google

# =====================================
# Whisper モデル選択（デフォルト）
# =====================================
# コマンドライン実行時に --whisper-model オプションで上書き可能
# 選択肢:
# - kotoba: 日本語特化（推奨） - kaiinui/kotoba-whisper-v2.0-mlx
# - mlx: 汎用高精度 - mlx-community/whisper-large-v3-mlx
# - openai: 標準実装 - openai/whisper large-v3
DEFAULT_WHISPER_MODEL=mlx-community
# OpenAI Whisper API を使う場合のモデル（フォールバック含む）
OPENAI_WHISPER_MODEL=whisper-large-v3-mlx

# =====================================
# その他の設定
# =====================================

# LLMリクエスト共通のタイムアウト秒数（CLIの --llm-timeout で上書き可能）
# 長尺音声で OpenAI Whisper API がタイムアウトする場合は 120 付近まで引き上げ推奨
LLM_REQUEST_TIMEOUT=30

# ブロック分割設定
# 長時間音声を処理する際のブロックサイズ
MAX_BLOCK_CHARS=1200      # 1ブロックあたりの最大文字数
MAX_BLOCK_DURATION=30     # 1ブロックあたりの最大秒数

# タイムスタンプアライメント設定（CLIの --align-thresholds / --align-gap 等で上書き推奨）
FUZZY_MATCH_THRESHOLD=90  # Fuzzy Matching の類似度閾値（%）※旧設定（現行はCLIで複数閾値指定可）

# ログ設定
LOG_LEVEL=INFO            # ログレベル: DEBUG, INFO, WARNING, ERROR
ENABLE_DETAILED_LOGS=true # 詳細ログを有効にする

# 出力設定
OUTPUT_DIR=./output       # デフォルトの出力ディレクトリ
TEMP_DIR=./temp           # 一時ファイルの保存先
LOG_DIR=./logs            # ログファイルの保存先
