# Two-Pass Workflow with Word-Boundary Splitting: Concrete Example

このドキュメントでは、提案する「単語境界分割 (Word-Boundary Splitting)」ロジックが、実際のデータをどのように処理するかをステップバイステップで示します。

## 1. Initial Input (Whisper Output)
Whisperから出力された、単語ごとのタイムスタンプ付きデータです。
ここでは、少し早口で喋っているが、途中に少し間があるケースを想定します。

**Raw Text:**
「えー、今日はですね、あのー、非常に良い天気なので、外でランチを食べようと思います。」

**Word Timestamps (JSON):**
```json
[
  {"index": 0, "word": "えー", "start": 0.0, "end": 0.5},
  {"index": 1, "word": "、", "start": 0.5, "end": 0.6},
  {"index": 2, "word": "今日", "start": 0.6, "end": 1.0},
  {"index": 3, "word": "は", "start": 1.0, "end": 1.2},
  {"index": 4, "word": "ですね", "start": 1.2, "end": 1.8},
  {"index": 5, "word": "、", "start": 1.8, "end": 1.9},
  {"index": 6, "word": "あのー", "start": 2.5, "end": 3.5},  // ここに0.6秒の間 (1.9-2.5)
  {"index": 7, "word": "、", "start": 3.5, "end": 3.6},
  {"index": 8, "word": "非常", "start": 3.6, "end": 4.0},
  {"index": 9, "word": "に", "start": 4.0, "end": 4.2},
  {"index": 10, "word": "良い", "start": 4.2, "end": 4.6},
  {"index": 11, "word": "天気", "start": 4.6, "end": 5.0},
  {"index": 12, "word": "な", "start": 5.0, "end": 5.2},
  {"index": 13, "word": "ので", "start": 5.2, "end": 5.6},
  {"index": 14, "word": "、", "start": 5.6, "end": 5.7},
  {"index": 15, "word": "外", "start": 5.7, "end": 6.0},
  {"index": 16, "word": "で", "start": 6.0, "end": 6.2},
  {"index": 17, "word": "ランチ", "start": 6.2, "end": 6.8},
  {"index": 18, "word": "を", "start": 6.8, "end": 7.0},
  {"index": 19, "word": "食べ", "start": 7.0, "end": 7.4},
  {"index": 20, "word": "よう", "start": 7.4, "end": 7.7},
  {"index": 21, "word": "と", "start": 7.7, "end": 7.9},
  {"index": 22, "word": "思い", "start": 7.9, "end": 8.3},
  {"index": 23, "word": "ます", "start": 8.3, "end": 8.6},
  {"index": 24, "word": "。", "start": 8.6, "end": 8.7}
]
```

---

## 2. Pass 1: Cleaning (LLM)
LLMがフィラー（「えー」「あのー」）を削除し、文章を整えます。
**LLM Instruction:** `delete 0-1 ("えー、")`, `delete 6-7 ("あのー、")`

**Updated Word List (Internal State):**
削除された単語はリストから消えますが、残った単語の `start`/`end` は**元のまま維持**されます。

| New Index | Original Word | Start | End | Note |
| :--- | :--- | :--- | :--- | :--- |
| 0 | 今日 | 0.6 | 1.0 | |
| 1 | は | 1.0 | 1.2 | |
| 2 | ですね | 1.2 | 1.8 | |
| 3 | 、 | 1.8 | 1.9 | |
| (Gap) | | 1.9 | 3.6 | **ここに1.7秒の無音区間が発生 (削除分含む)** |
| 4 | 非常 | 3.6 | 4.0 | |
| 5 | に | 4.0 | 4.2 | |
| 6 | 良い | 4.2 | 4.6 | |
| 7 | 天気 | 4.6 | 5.0 | |
| 8 | な | 5.0 | 5.2 | |
| 9 | ので | 5.2 | 5.6 | |
| 10 | 、 | 5.6 | 5.7 | |
| 11 | 外 | 5.7 | 6.0 | |
| 12 | で | 6.0 | 6.2 | |
| 13 | ランチ | 6.2 | 6.8 | |
| 14 | を | 6.8 | 7.0 | |
| 15 | 食べ | 7.0 | 7.4 | |
| 16 | よう | 7.4 | 7.7 | |
| 17 | と | 7.7 | 7.9 | |
| 18 | 思い | 7.9 | 8.3 | |
| 19 | ます | 8.3 | 8.6 | |
| 20 | 。 | 8.6 | 8.7 | |

---

## 3. Pass 2: Segmentation (LLM)
LLMが17文字制限を意識して行分割を行います。
今回はあえて、LLMが「1行に詰め込みすぎた」ケース（または17文字ギリギリの長い行）を想定します。

**LLM Output (JSON):**
```json
{
  "lines": [
    {"from": 0, "to": 9, "text": "今日はですね、非常に良い天気なので"},  // 16文字 (OK)
    {"from": 11, "to": 20, "text": "外でランチを食べようと思います"}      // 15文字 (OK)
    // index 10 ("、") は行末削除ルールで消えたと仮定
  ]
}
```

---

## 4. Local Processing: Timestamp Assignment
ここが重要です。LLMの出力結果を、**単語リストのタイムスタンプ**にマッピングします。

### Line 1: "今日はですね、非常に良い天気なので"
- **Range:** Index 0 ("今日") to Index 9 ("ので")
- **Start Time:** `words[0].start` = **0.6s**
- **End Time:** `words[9].end` = **5.6s**

**ここでのポイント:**
この行の中には、Index 3 ("、") と Index 4 ("非常") の間に **1.9s 〜 3.6s の大きなギャップ（無音 + 削除されたフィラー区間）** があります。
しかし、字幕としては「今日はですね、非常に良い天気なので」と一文で表示したい場合、このギャップを含んで表示し続けるのが自然です（あるいはギャップで分割するか）。

もしここで「17文字制限を超えてしまった」場合（例：「今日はですね、非常に良い天気なので、外で」まで入ってしまった場合）をシミュレーションします。

#### 【仮想シナリオ】もしLLMが長すぎる行を返したら？
**Bad Line:** "今日はですね、非常に良い天気なので、外で" (19文字 -> **Over 17 chars**)
- **Range:** Index 0 to 12
- **Start:** 0.6s
- **End:** 6.2s

**従来の「線形補間」の問題点:**
0.6s〜6.2s (5.6秒間) を19文字で等分します。
1文字あたり約0.29秒。
17文字目の「で」が表示されるべき時間は...計算が複雑になり、かつ**実際の音声（"外で" は 5.7s から発話）とズレます**。

**提案する「単語境界分割」の処理:**
1. **文字数オーバーを検知**: 19文字 > 17文字。
2. **分割ポイントの探索**:
   単語リストを前から走査し、17文字を超えない最大の単語を探します。
   - "今日はですね、非常に良い天気なので" (Index 0-9) -> 16文字 (**Keep**)
   - 次の単語 "、" (Index 10) -> 17文字 (Just) -> 行末句読点なので削除対象
   - 次の単語 "外" (Index 11) -> 19文字 (**Over**)
3. **分割実行**:
   Index 9 ("ので") で分割します。

   - **Split Line 1**: Index 0-9 "今日はですね、非常に良い天気なので"
     - Start: `words[0].start` = **0.6s**
     - End: `words[9].end` = **5.6s**
   
   - **Split Line 2**: Index 11-12 "外で" (残りの部分)
     - Start: `words[11].start` = **5.7s**
     - End: `words[12].end` = **6.2s**

**結果:**
時間が**完全に元の音声と一致**します。
無理やり引き伸ばされたり、無音区間が文字で埋められたりしません。

---

## 5. Final SRT Output
上記の処理（Pass 2の正常な出力）をSRTにします。

**Line 1**
- Text: "今日はですね、非常に良い天気なので"
- Start: 0.6s
- End: 5.6s

**Line 2**
- Text: "外でランチを食べようと思います"
- Start: 5.7s (Index 11 "外" の start)
- End: 8.7s (Index 20 "。" の end)

```srt
1
00:00:00,600 --> 00:00:05,600
今日はですね、非常に良い天気なので

2
00:00:05,700 --> 00:00:08,700
外でランチを食べようと思います
```

## まとめ
この方式の最大のメリットは、**「LLMはテキストの区切り位置（インデックス）を決めるだけ」** に徹し、**「時間はすべてWhisperの生データ（Word Timestamps）を参照する」** 点です。
これにより、どれだけLLMがテキストを加工しても、最終的な字幕の表示タイミングは**音声と1ミリ秒もズレません**。
