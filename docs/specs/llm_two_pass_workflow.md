# LLM二段階ワークフロー案（整形 → 17文字分割）

目的: タイムコードの伸びを防ぎつつ、LLM精度を活かすため、処理を2パスに分割する。LLMは内容修正と行分割を担当し、時間計算はローカルで行う。

## 全体フロー
1. Whisperで文字起こし（全文テキスト + word-levelタイムスタンプを取得）。
2. パス1（LLM整形）: 誤字/フィラー除去・語尾調整など内容をクリーンにする。LLMは「単語インデックス」を使った編集指示（置換・削除のみ）を返す。
3. ローカル適用: 置換/削除を反映し、元の start/end を維持（挿入時のみ前後の中点で補間）。
4. パス2（LLM分割）: パス1後の単語列を入力し、17文字幅を守る行区切りをインデックス範囲で返す（`lines` JSONのみ。`[WORD:]`タグは廃止）。
5. ローカルでSRT生成: 行開始=最初の単語start、行終了=最後の単語end。幅超過があればローカルで再分割し時間を区間内で線形補間し、巻き戻りはクランプ。

## 入出力イメージ
- 単語リスト例（Whisper出力を保持）:
  ```json
  {"index": 0, "word": "私", "start": 0.00, "end": 0.18}
  ```
- LLMパス1出力例（編集指示）:
  ```json
  {
    "operations": [
      {"type": "replace", "start_idx": 3, "end_idx": 4, "text": "決めていて"},
      {"type": "delete", "start_idx": 20, "end_idx": 20}
    ]
  }
  ```
- LLMパス2出力例（行分割、タグ無し）:
  ```json
  {
    "lines": [
      {"from": 0, "to": 10, "text": "私は大学の12月ぐらい"},
      {"from": 11, "to": 25, "text": "政治家になろうと決めていて"}
    ]
  }
  ```

## パス1プロンプト（文章整形専用：置換・削除のみ）
```
あなたはプロの字幕エディターです。以下の単語列を順番を変えずに最小限の修正だけ加えてください。
- 入力は全文テキストと、各単語のインデックス付きリストです。
- 許可される操作: replace, delete（挿入は禁止。音声に無い単語を足さないこと）。
- 単語の順序は変えないでください。
- 出力は JSON で、operations 配列のみを返してください。

入力テキスト:
{raw_text}

単語リスト（index:word）:
{indexed_words}

出力フォーマット例:
{"operations":[{"type":"replace","start_idx":10,"end_idx":11,"text":"カレーライス"},{"type":"delete","start_idx":25,"end_idx":25}]}
追加の説明は不要です。
```

## ローカル適用ルール（パス1後）
- replace（例）  
  - 置換前: `i10「決め」 start=8.00 end=8.30` / `i11「て」 start=8.30 end=8.45`  
  - LLM指示: `replace 10-11 -> "決めて"`  
  - 適用後: start/end は `8.00-8.45` をそのまま継承し、テキストだけ「決めて」に置換（時間を動かさない）。
- replace（1語だけ書き換えの例）  
  - 置換前: `i5「カレーす」 start=2.10 end=2.40`  
  - LLM指示: `replace 5-5 -> "カレーライス"`  
  - 適用後: start/end は `2.10-2.40` のまま、テキストのみ「カレーライス」に置換（時間を動かさない）。
- delete（例）  
  - 置換前: `i20「えー」 start=12.10 end=12.30`  
  - LLM指示: `delete 20-20`  
  - 適用後: i20を削除。隣接語の時間は触らず、行計算時に自然に詰まる（時間を動かさない）。

## パス2プロンプト（17文字分割専用・実装用）
```
# Role
あなたは熟練の動画テロップ編集者です。
提供されたテキストを、視聴者が最も読みやすいリズムで読めるように、以下の【思考ワークフロー】に従って処理し、行のインデックス範囲を JSON で返してください。

# Constraints (制約)
- 1行の最大文字数：全角17文字
- 出力形式：JSON の lines 配列のみ（例を参照）
- 禁止事項：行末の句読点（、。）は必ず削除すること。文中の句読点は残してもよい。
- 単語の順序を変えない。結合もしない。

# Thinking Workflow (思考ワークフロー)
## Step 1: チャンク分解 (Chunking)
入力されたテキストを、文節や意味の最小単位（チャンク）に分解する。句読点（、。）や接続助詞（〜て、〜が、〜ので、〜から）を強い区切りとして扱う。

## Step 2: 行の構築と決定 (Line Building)
チャンクを前から順に追加し、以下の判定を行う。
1. 文字数オーバー: 現バッファ＋次チャンクが17文字を超えるなら改行。
2. 文脈区切り: 17文字以内でも、読点・強い切れ目（〜ます、〜です、〜だ等）・接続助詞で終わるなら改行。

## Step 3: クリーニング (Cleaning)
行末の句読点（、。）を削除。文中の句読点は残してよい。

# Input
単語リスト（index:word）:
{indexed_words_after_pass1}

# Output  
以下のJSONだけを返してください（コードフェンス不要・追加説明不要）:  
{"lines":[{"from":0,"to":10,"text":"私は大学の12月ぐらい"},{"from":11,"to":25,"text":"政治家になろうと決めていて"}]}
```

## 時間計算（ローカル）
- 行開始: 行の最初の単語 start
- 行終了: 行の最後の単語 end
- 17文字幅チェック: 超過したら行内でローカル再分割し、時間は区間内で線形補間
- 巻き戻り防止: start < 前行end の場合は start を前行end にクランプ
- 末尾が音声尺を超えた場合は音声最終時刻でクランプ

## Pass3（最終チェック、常時実行）
- issues が無くても必ず実行し、5〜17文字の範囲と自然な改行を最終確認。
- 1〜4文字の極端に短い行や引用分割を検出したら統合。
- 要約・翻訳・意訳、語句の追加/削除は禁止。語の途中で切れている箇所は必ず連結。
- 改行優先度: (1)「。?!」直後 → (2)「、」直後 → (3) 接続助詞・係助詞など句が自然に切れる後ろ。迷う場合は改行しない。

## Pass4（長さ違反行のみ再LLM、ローカル分割なし）
- Pass3後に5文字未満または17文字超の行だけを再度LLMにかけ直し、複数行に分割させる。
- 出力が空/不正の場合は元行をそのまま維持する（ローカルでの強制分割はしない）。
- モデルは `LLM_PASS4_MODEL`（未指定時は Pass3 と同じ）を使用。

## この方式のメリット
- タイムコード計算をLLMに任せず、Whisperのタイムスタンプに固定するため尺が伸びにくい
- LLMの強み（表現修正と自然な改行）を2パスで活かせる
- `[WORD:]`タグやRapidFuzzに依存せず、インデックス直マッピングでシンプルに保守できる
