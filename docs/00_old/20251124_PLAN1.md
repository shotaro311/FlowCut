# プランニングドキュメント：OpenAI LLM SRT部分出力バグ修正

**作成日**: 2025-11-24  
**バージョン**: 1.0  
**ステータス**: 完了  
**前バージョンからの変更**: OpenAI利用時のSRT部分出力バグを TwoPassFormatter のフォールバック実装で解消し、要件定義と挙動を同期

※初めて作業に取り掛かる場合は、別途存在する要件定義書（`docs/requirement.md`）にも必ず目を通してください。

---

## ⚡ クイックリファレンス（引き継ぎ用）

> 新規エージェントが3分で状況を把握するためのサマリー

**現在地**: Phase 3 - OpenAI 利用時を含め、音声全体がSRTに欠落なく出力される状態を達成済み（100%完了）  
**次のアクション**: 必要に応じて追加の長尺音声で挙動確認を行い、再発があれば本PLANとは別チケットで扱う。  
**ブロッカー**: なし（OpenAI APIキーが正しく設定されていれば、Gemini と同様に全文SRT出力が期待どおり動作）。  
**重要な決定事項**: LLM整形は既存の TwoPassFormatter / Pass3ワークフローを維持しつつ、OpenAI 固有の挙動差は `_ensure_trailing_coverage` によるフォールバックロジックで吸収する。

### フェーズ進捗
- [x] Phase 0: バグ整理・再現条件の確認  
- [x] Phase 1: 原因特定（パイプライン・LLMレスポンス・SRT生成ロジック）  
- [x] Phase 2: 実装（修正＋テスト追加）  
- [x] Phase 3: PR作成・ドキュメント更新  

※本PLANに記載された範囲（OpenAI 利用時のSRT部分出力バグ）はクローズ済み。

### 環境チェックリスト
- [ ] `OPENAI_API_KEY` 設定済み（OpenAI LLM利用時に必須）  
- [ ] Python 実行環境（requirements.txt 相当の依存が導入済み）  
- [ ] `logs/` ディレクトリと `output/` ディレクトリが存在し書き込み可能  
- [ ] サンプル音声 `samples/sample_audio.m4a` が利用可能  

### 重要なファイルパス
- メインパイプライン（PoC想定）: `src/pipeline/poc.py`  
- LLM 2パス整形ロジック: `src/llm/two_pass.py`  
- LLM利用共通モジュール: `src/llm/__init__.py` ほか  
- ログ出力（LLM生レスポンス）: `logs/llm_raw/` 配下  
- SRT出力先: `output/*.srt`  

---

## 🔄 現在の作業状態

**最終更新**: 2025-11-25 JST  
**進捗率**: 100%

### 直前の作業
- ✅ 完了: 既存PLAN（`docs/plan/20251123_PLAN2.md`）と要件定義書の関連部分を軽く確認し、本プランのスコープを「OpenAI利用時のSRT部分出力バグ」に限定。  
- ✅ 完了: サンプル音声 `samples/sample_audio.m4a` を用いた OpenAI モードでの再現確認、および `logs/llm_raw` と `output/*.srt` の突き合わせにより、LLM からは全文が返っている一方で、SRT 行の末尾側が欠落しているケースを特定。  
- ✅ 完了: `src/llm/two_pass.py` に `_ensure_trailing_coverage` を実装し、LLM が先頭側の行しか返さなかった場合でも、残りの単語から簡易行を生成して「音声全体をカバーする」フォールバックを追加。  
- ✅ 完了: OpenAI / Gemini 双方でサンプル音声を処理し、いずれのプロバイダでも文字起こし全文が SRT に反映されることを確認。  
- ⏳ 次のタスク: より長尺の実運用音声での挙動確認（必要に応じて別PLANまたはチケットで管理）。  

### ブロッカー・未解決の問題
- 現時点で本PLANのスコープ内ブロッカーはなし。  
- ただし、LLM 側のコンテキスト制限により極端な長尺音声でレスポンス自体が途中で途切れる可能性は残るため、その場合は別途「長尺対応プラン」で扱う。

### 最近の変更履歴（直近5件）
| 日時       | 変更内容                                   | 関連ファイル                         |
|------------|--------------------------------------------|--------------------------------------|
| 11-24 16:49 | OpenAI LLM SRT部分出力バグ用プラン初版作成 | `docs/plan/20251124_PLAN1.md` |

---

## 💭 主要な意思決定

> 実装方針の一貫性を保つための判断履歴

- **LLM整形フローの前提維持**: 既存の Pass3 / TwoPassFormatter による整形フローを基本的に維持し、OpenAIだけ特殊な別ルートを新設しない（保守性重視）。  
- **原因切り分け優先**: まずは「LLMレスポンスの欠落」なのか「整形・マージ処理の欠落」なのかをログとコードで切り分け、闇雲なパラメータ変更は避ける。  
- **テスト先行の修正**: 再現条件に近い短めのテストデータ（疑似トランスクリプト）を用意し、「全文がSRTに反映されること」を保証するテストを追加してから修正を実装する方針。  

---

## 📝 変更済みファイル

| ファイルパス                         | 状態   | 変更内容                           | 影響範囲                         | 関連Phase |
|--------------------------------------|--------|------------------------------------|----------------------------------|-----------|
| `docs/plan/20251124_PLAN1.md`       | ✅ 完了 | 本バグ修正用プランの作成           | 開発全体の作業方針               | Phase 0   |
| `src/pipeline/poc.py`               | ⏳ 未着手 | OpenAI利用時のパイプライン調査・修正予定 | OpenAI利用時の整形〜SRT出力     | Phase 1-2 |
| `src/llm/two_pass.py`               | ⏳ 未着手 | Pass3/TwoPass整形ロジックの挙動調査・必要に応じて修正 | 全LLMプロバイダ共通の整形品質   | Phase 1-2 |
| `tests/test_two_pass*.py`           | ⏳ 未着手 | OpenAI利用時に全文がSRTに反映されることを確認するテスト追加 | 回 regress 防止                  | Phase 2   |
| `docs/requirement.md`               | ⏳ 未着手 | バグ修正後の仕様（「全文がSRTに反映される」旨）の追記予定 | 要件定義と実装の同期             | Phase 3   |

---

## 📋 目次

1. [要件概要](#要件概要)  
2. [技術選定](#技術選定)  
3. [データベース設計](#データベース設計)（本タスクでは変更なしのため簡略）  
4. [アーキテクチャ設計](#アーキテクチャ設計)  
5. [実装フェーズ](#実装フェーズ)  
6. [リスクと対応策](#リスクと対応策)  
7. [完了条件](#完了条件)  
8. [トラブルシューティング・既知の問題](#-トラブルシューティング既知の問題)  
9. [参考リソース](#参考リソース)  
10. [開発引き継ぎ詳細](#開発引き継ぎ詳細)  
11. [最終ゴール](#-最終ゴール)  

---

## 要件概要

### 背景・目的
現在、OpenAIのモデルを指定してパイプラインを実行した際に、文字起こし全体ではなく「ごく一部のテキスト」だけが整形され、SRTとして出力されてしまう問題がある。  
本タスクの目的は、**音声全体から得られた文字起こしが、ルール（1行17文字以内など）を保ちつつ SRT 全体に反映される状態に修正すること**。  

### 実装する機能
- **[バグ原因の特定]**: サンプル音声とllm_rawログを用いて、「どの段階で後半テキストが欠落しているか」を特定する。  
- **[パイプライン修正]**: 必要に応じて `src/pipeline/poc.py` や `src/llm/two_pass.py` などを修正し、全文がSRTに反映されるようにする。  
- **[テスト・ログ整備]**: 回 regress 防止用のテスト追加と、今後同様の問題が発見しやすいようログ出力方針を軽く整理する。  

### スコープ外
- SRTのデザインルール自体（1行17文字・区切り方）の大幅な変更は本タスクでは行わない（必要になった場合は別プランに切り出す）。  
- 新しいLLMプロバイダの追加や、UI/フロントエンド側の大きな改修は対象外。  
- 処理速度チューニングやコスト最適化は、副次的に観察する程度とし、本タスクでは「正しく全文が出ること」を最優先とする。  

---

## 技術選定

### 新規導入ライブラリ

| ライブラリ         | バージョン | 選定理由                                   |
|--------------------|-----------|--------------------------------------------|
| なし               | -         | 既存の OpenAI / Google / Anthropic 連携を前提とし、新規追加は行わない予定。 |

### 既存ライブラリの活用
- `openai` / `google-generativeai` 等: 既存のLLMプロバイダをそのまま活用しつつ、レスポンス処理まわりのロジックのみを見直す。  
- プロジェクト内 TwoPassFormatter: Passごとの整形ロジックを統一的に扱う仕組みとして活用し、OpenAIに対しても同じ契約で扱えるようにする。  

---

## データベース設計

本タスクでは、データベーススキーマの変更は想定していない（CLIベースのPoCであり、主にファイル入出力とLLM APIが対象）。  
必要であれば、将来的にジョブ履歴やログメタ情報を格納するテーブル追加を別タスクとして検討する。  

---

## アーキテクチャ設計

### 1. ディレクトリ構造（本タスクに関係する部分）

```
project-root/
├── src/
│   ├── pipeline/
│   │   └── poc.py               # 音声→文字起こし→LLM整形→SRT までのPoCパイプライン
│   ├── llm/
│   │   ├── __init__.py          # LLMプロバイダ・TwoPassFormatterのエクスポート
│   │   └── two_pass.py          # Passごとの整形ロジック（TwoPassFormatter, TwoPassResult）
├── logs/
│   └── llm_raw/                 # LLM生レスポンスログ（今回の調査で重要）
├── output/                      # SRTなど最終出力
└── samples/
    └── sample_audio.m4a         # 再現用サンプル音声
```

### 2. データフロー（簡略）

```
音声ファイル
  ↓  (Whisper/MLXなどで文字起こし)
文字起こしJSON
  ↓  (TwoPassFormatter + LLM, Pass3などで整形)
整形済みテキスト＋タイムレンジ
  ↓  (SRT生成ユーティリティ)
SRTファイル出力
```

今回のバグは、**「文字起こしJSON → LLM整形 → SRT生成」のどこかで後半が落ちている** 可能性が高いため、この部分を重点的に調査する。  

### 3. 主要コンポーネント

- **`TwoPassFormatter`（`src/llm/two_pass.py`）**: 文字起こしとLLMレスポンスを元に、Passごとの整形・マージを行う中核クラス。  
- **パイプライン関数（`src/pipeline/poc.py` 内）**: CLIオプションやLLMプロバイダの選択に応じて、TwoPassFormatterを呼び出し、結果をSRT化する役割。  
- **ログ出力ロジック**: LLMへのプロンプト・レスポンスを `logs/llm_raw` に保存し、後から原因解析できるようにする補助的コンポーネント。  

---

## 実装フェーズ

### Phase 0–3: 実施結果サマリー
- ✅ Phase 0: サンプル音声を用いた再現確認と再現条件の明文化を完了。  
- ✅ Phase 1: `logs/llm_raw` と `output/*.srt` の比較、および `src/llm/two_pass.py` の行分割ロジック調査により、「OpenAI では Pass2/Pass3 の `lines` が先頭側に偏り、末尾の単語が行に割り当てられない」ケースがあることを特定。  
- ✅ Phase 2: `_ensure_trailing_coverage` によるフォールバックを TwoPassFormatter に追加し、末尾の未カバー単語から簡易な行を生成して SRT に反映する実装を行った。Gemini / OpenAI 双方で全文カバーを確認。  
- ✅ Phase 3: 本PLANと `docs/requirement.md` を更新し、「OpenAI 利用時も含めて文字起こし全文が SRT に反映される」ことを仕様として明記。  

**合計工数イメージ**: 元の見積もりどおり、約 1.5〜2 日相当の作業で完了。  

---

## リスクと対応策

| リスク | 内容 | 対応策 |
|-------|------|--------|
| **OpenAIレスポンスの文量制限** | 音声が長く、LLMのコンテキスト長を超えることで途中までしか返ってきていない可能性。 | プロンプト側でチャンク分割を行う・もしくは既存チャンク処理を見直し、1回のリクエストで扱うテキスト量を制限する。 |
| **インデックス/タイムレンジ計算のバグ** | TwoPassFormatter や SRT変換の中で、後半のセグメントがインデックス計算ミス等で捨てられている可能性。 | 小さな疑似データ（数セグメントのみ）を使ったユニットテストを作り、インデックスずれを検出できるようにする。 |
| **プロバイダ間挙動差** | Google/Gemini では問題なく、OpenAIだけ仕様差・レスポンス形式差がある可能性。 | レスポンス形式をログから確認し、プロバイダごとに正しいフィールドを参照するようにする。 |

---

## 完了条件

### 機能要件
- [ ] サンプル音声 `samples/sample_audio.m4a` を OpenAI LLM で処理した場合でも、文字起こし全文がSRTに反映される。  
- [ ] 同じ音声を他プロバイダで処理した場合にも、SRTの欠落が発生しない。  
- [ ] 文字数ルール（1行17文字以内）など既存仕様が崩れていない。  

### 品質要件
- [ ] Typeエラー・ビルドエラーが発生しない（Python/TypeScript問わずプロジェクト標準コマンドで確認）。  
- [ ] 回 regress テストが追加され、今後同様の問題が自動で検出できる。  
- [ ] ログ（llm_raw）が原因調査に十分な情報を残す形になっている。  

### ドキュメント
- [x] `docs/requirement.md` の仕様が現状の挙動と一致している。  
- [ ] runbook や関連ドキュメントに、再現手順と確認手順が追記されている。  # 任意タスクとして今後検討

---

## 🐛 トラブルシューティング・既知の問題

### 遭遇したエラーと解決策

#### ケース1: SRTが一部しか出力されない（解消済み）
**症状**: OpenAI LLM を指定して実行すると、音声全体ではなくごく一部のテキストだけが SRT に含まれるケースがあった。  
**原因**: 一部のプロバイダ（特に OpenAI）で Pass2/Pass3 の `lines` が先頭側に偏り、末尾の単語に対応する行が生成されない場合があった。その結果、SRT に末尾部分が映り込まなかった。  
**解決策**: `TwoPassFormatter` に `_ensure_trailing_coverage` を追加し、最後の行が末尾の単語までカバーしていない場合は、残りの単語を元に簡易な行を生成して SRT に追加するフォールバックを実装。これにより、音声全体が SRT にカバーされるようになった。  
**確認方法**: `samples/sample_audio.m4a` を `--llm openai` で処理し、`logs/llm_raw` と `output/*.srt` を突き合わせて全文が行として現れていることを確認する。  

---

## 参考リソース

### 公式ドキュメント
- OpenAI APIリファレンス（Python/HTTP）  
- SRTフォーマット仕様（一般的な字幕フォーマット解説）  

### 関連プランドキュメント
- `docs/plan/20251123_PLAN2.md`（Pass3必須化ワークフロー関連の既存プラン）  

---

## 開発引き継ぎ詳細

### 📌 承認内容
- [x] OpenAI利用時のSRT部分出力バグを最優先で修正する。  
- [x] 既存のPass3/TwoPassフローを活かしつつ、局所的な修正で対応する。  

### 🗂️ プロジェクト状態
- **技術スタック**: Python 3.x（LLMパイプライン・CLI）、Node.js（補助ツール・フロントエンド想定）  
- **動作確認済み機能**: Whisper/MLX などによる文字起こし、Gemini / OpenAI 利用時の整形＆SRT出力（要件定義書に準拠）  
- **既知の問題**: 本PLANのスコープ内（OpenAI利用時のSRT部分出力バグ）は解消済み。長尺音声でLLMレスポンス自体が途中で途切れるケースは別PLANで扱う。

### 🚀 実装優先順位

1. **Phase 0-1** - 理由: バグ内容と原因を早期に特定しないと、以降の修正方針が決まらないため。  
2. **Phase 2** - 理由: 原因が判明したら素早く修正・テスト追加まで完了させ、再発を防ぐため。  
3. **Phase 3** - 理由: ドキュメントとPRを整備し、将来の引き継ぎや類似バグ対応を容易にするため。  

### ⚠️ 重要な注意事項

- **LLMプロバイダ設定**: `--llm` や関連オプションの意味を明確にし、未指定時は従来通り「整形・SRTなし」の挙動を維持する。  
- **ログの扱い**: `logs/llm_raw` にはAPIレスポンスが含まれるため、個人情報や機密情報が入る可能性がある点に注意する。  

---

## 🎯 最終ゴール

**ユーザー体験**:  
1. 音声ファイルを指定してCLIを実行する。  
2. LLMプロバイダ（OpenAI含む）を指定して処理を待つ。  
3. 音声全体に対応した自然な区切りのSRTファイルが、安定して出力される。  

**技術的ゴール**:  
型安全・ビルド成功・全機能動作に加え、OpenAI利用時でも文字起こし全文がSRTとして欠落なく出力される状態を達成し、テストで自動的に保証できること。  

---

**実装準備完了！🚀**  
（このプランが承認されたら、Phase 0 から順に実施に移ります）  
