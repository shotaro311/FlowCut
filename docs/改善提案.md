# 要件定義の改善案（レビュー済み）

このドキュメントは要件定義書の改善提案をまとめたものです。
各項目について要件定義への反映状況を記載しています。

---

## 1. 17文字カウントと字幕行構成

### 提案内容
- **全角換算を明文化**: `unicodedata.east_asian_width`でFullwidth/Wideを1文字、Halfwidth/Narrow/Neutralを0.5文字として計測し、合計を四捨五入して17文字以内に収めると仕様に追記する。
- **1行・2行構成の選択仕様（ルール明確化）**: SRTの各ブロックは「1行」または「2行」から選べるが、どちらの場合も1行あたりの最大は全角換算で17文字以内とする（全角17文字≒半角34文字）。2行指定時は「1行ずつ最大17全角まで、2行合計で33全角（四捨五入）」を超えないよう分割し、もし追加の行が必要な場合は、新しいSRTブロックとして繰り返し処理する。ブロック数や行数に関係なく「1行＝最大17全角」というルールが共通であることを明示する。
- **改行優先順位**: 読点→助詞後→意味の区切りの順で改行を検討し、「17文字を超過した場合は、その時点で強制的に改行する」のではなく、一度その前後の行の文章構造を再分析し、自然な意味のまとまりごとに、各行が17文字以内となるようバランスよく再調整する仕様とする。実装・レビュー時はこの優先順位と分割調整方針を指針とする。

### 採用状況: ✅ **採用（一部修正）**

**要件定義への反映箇所:** `docs/要件定義.md` - Step 3-1

**採用内容:**
- 17文字カウント仕様を明確化
  - `unicodedata.east_asian_width` 使用
  - Fullwidth/Wide: 1文字、Halfwidth/Narrow/Neutral: 0.5文字
  - 四捨五入で17文字以内

**修正点:**
- 「2行合計で33全角」という表現を削除（各行独立して17文字以内）
- 改行優先順位はLLMのプロンプトで指定（実装ロジックではなく、LLMに任せる）

---

## 2. `[WORD: 単語]`タグ後処理フロー

### 提案内容
1. LLM出力から行テキストと`WORD`タグを分離したJSON（`[{text, anchor_word}]`）を生成。
2. SRT書き出し前に字幕本文からタグを除去し、`anchor_word`だけをアライメント用に保持する。
3. タグ削除後に再度17文字チェックを行い、超過した行は自動再分割（一度その前後の行の文章構造を再分析し、自然な意味のまとまりごとに、各行が17文字以内となるようバランスよく再調整）してログ出力。
4. 最終SRT生成はタグなしテキストを使用し、アライメント処理ではJSON内の`anchor_word`を参照する流れを要件に明記する。

### 採用状況: ✅ **完全採用**

**要件定義への反映箇所:** `docs/要件定義.md` - Step 3-1

**採用内容:**
- タグ分離→JSON化→17文字再検証の完全なフロー
- 表示テキストとアライメント情報の分離
- 超過行の自動再分割と`logs/resplit.log`への記録
- 最終データ構造を明確に定義

**評価:** この提案は非常に妥当で、実装の根幹となる設計です。

---

## 3. タイムスタンプ照合の冗長アンカー

### 提案内容
- **複数アンカー**: 各行で「先頭語・中央語・末尾語」を最大3語保持し、照合時は末尾→先頭→中央の順で試行。RapidFuzzの類似度閾値は末尾90%、先頭85%、中央80%など段階的に設定する。
- **行シグネチャ**: 行テキストを正規化（ひらがな統一・句読点除去）し、3語を連結したシグネチャを作成。単語一致に失敗した場合はシグネチャのサブシーケンス検索でフォールバックする。
- **仮タイムスタンプ**: すべて失敗した場合は直前行終了+0.3秒〜+1.0秒で仮タイムスタンプを作成し、`logs/alignment_warnings.json`に行番号を記録してユーザーに警告する仕様を提案。

### 採用状況: ⚠️ **段階的採用（フェーズ1は簡易版）**

**要件定義への反映箇所:** `docs/要件定義.md` - Step 3-2

**フェーズ1（最優先実装）:**
- ✅ 末尾アンカーのみを使用
- ✅ 完全一致 → Fuzzy Matching（90%閾値）→ 仮タイムスタンプ
- ✅ 失敗ケースを`logs/alignment_warnings.json`に記録

**フェーズ2（失敗率5%以上の場合のみ）:**
- 先頭・中央アンカーを追加
- 閾値を段階的に調整（末尾90%、先頭85%、中央80%）

**見送り（過剰設計）:**
- ❌ 行シグネチャ（サブシーケンス検索）
  - 理由: RapidFuzzの`partial_ratio`で同等の結果が得られる可能性が高い
  - 実装が複雑で、まずはシンプルな方法で検証すべき

**評価:** 複数アンカーのアイデアは良いが、まず末尾アンカーのみで実装し、実データで失敗率を測定してから拡張すべき。

---

## 4. CLI `--model`指定の整理

### 提案内容
- `--model`は `kotoba | mlx | openai` の3択に統一し、デフォルトを`kotoba`とする。
- 各値がどのリポジトリを参照するかをREADME/要件定義に表形式で追記（kotoba→`kaiinui/kotoba-whisper-v2.0-mlx`、mlx→`mlx-community/whisper-large-v3-mlx`、openai→`openai/whisper`）。
- small/medium/largeといったサイズ指定は廃止し、将来的に別チェックポイントを触りたい場合は追加オプション（例:`--mlx-checkpoint large-v3`）で記述する方針を示す。

### 採用状況: ✅ **採用（名称変更）**

**要件定義への反映箇所:** `docs/要件定義.md` - 4. UI/UX 要件

**採用内容:**
- オプション名を `--whisper-model` に変更（LLM選択と区別するため）
- `{kotoba|mlx|openai}` の3択
- デフォルト: `kotoba`
- 各モデルのリポジトリ情報を明記

**追加要素:**
- LLM選択用に `--llm {openai|google|anthropic}` オプションを追加
- `.env` ファイルでデフォルト値を設定可能に

**評価:** 非常に妥当な提案で、完全に採用しました。

---

## 5. OpenAI API送信ブロック戦略

### 提案内容
- **ブロック長**: 1ブロックは日本語1200文字（約600トークン）または音声30秒を上限にし、どちらかに達した時点で分割。
- **重複ウィンドウ**: 各ブロック末尾の3行を次ブロック冒頭にも含め、整形後は`line_id`で重複除去し、文脈断絶を防止。
- **リトライ指針**: API失敗時は指数バックオフ（1s/3s/5s）で最大3回リトライし、失敗ブロック番号・理由を標準出力とログに表示。長尺時は`--segment-seconds`でユーザーが上限を変更できるようにする。

### 採用状況: ✅ **採用（一部修正）**

**要件定義への反映箇所:** `docs/要件定義.md` - Step 2

**採用内容:**
- 1200文字または30秒でブロック分割
- 重複ウィンドウで文脈維持（末尾の1-2文を次ブロックに含める）
- 指数バックオフ（1s → 3s → 5s）で最大3回リトライ
- 失敗時は`temp/progress_{timestamp}.json`に保存
- `--resume`オプションで再開可能

**修正点:**
- 重複ウィンドウを「3行」から「1-2文」に変更（より柔軟に）
- `--segment-seconds`オプションは見送り（`.env`で設定可能に）

**評価:** 30分前後の動画に対応するため、ブロック分割は必須。提案は妥当で採用しました。

---

## 6. API障害・ネットワーク断対策

### 提案内容
- **フェイルセーフモード**: API連続失敗2回で自動的にオフラインモードへ切り替え、音声認識結果をそのままSRTに書き出して利用者へ警告する。
- **再実行ガイド**: 失敗時には「ネットワークを確認し、`python main.py --resume <ブロック番号>`を実行してください」と具体的な再開手順を表示。
- **タイムアウトとフォールバック**: 30秒応答が無い場合はリクエストをキャンセルし、GPT-4o-miniへフォールバック。それでも失敗したらユーザー通知とログ保存。
- **ログ保管**: `logs/failed_blocks.json`に時刻・ブロックID・エラー種別を保存し、非エンジニアでもサポート問い合わせに提示できるようにする。

### 採用状況: ⚠️ **一部採用（オフラインモードは却下）**

**要件定義への反映箇所:** `docs/要件定義.md` - Step 2エラーハンドリング

**採用内容:**
- ✅ 指数バックオフ（1s/3s/5s）で最大3回リトライ
- ✅ 処理済みブロックを`temp/progress_{timestamp}.json`に保存
- ✅ エラー終了時に具体的な再開手順を表示
- ✅ `logs/processing.log`に処理状況を記録

**却下内容:**
- ❌ 自動オフラインモード
  - **理由**: 音声認識テキストそのままでは17文字制約を満たさない
  - **代替策**: エラー終了して、ユーザーに再実行を促す（中途半端な出力より明確なエラーの方が良い）

**修正内容:**
- タイムアウト設定は実装時に検討（現時点では仕様化しない）
- LLMプロバイダー切り替えは手動で実施（`--llm`オプションで変更）

**評価:** 再開機能は重要だが、オフラインモードは要件を満たさないため却下。

---

## 追加採用事項（レビュー時に追加）

### 7. LLMプロバイダー選択機能

**提案:** 要件定義レビュー時にユーザーから提案

**内容:**
- OpenAI、Google、Anthropicの3社から選択可能
- `.env`ファイルでAPIキーとモデル名を事前設定
- `--llm {openai|google|anthropic}`で実行時に切り替え
- 非エンジニアでもモデル更新可能（コード変更不要）

**採用状況:** ✅ **完全採用**

**評価:**
- 特定プロバイダーの障害時に別プロバイダーへ切り替え可能
- コスト最適化が容易
- 将来のモデル更新に柔軟対応

---

## 総合評価

### ✅ 完全採用（フェーズ1で実装）
1. ✅ 17文字カウントの明確化
2. ✅ `[WORD: ]`タグ後処理フロー
3. ✅ CLI整理（`--whisper-model`、`--llm`）
4. ✅ ブロック分割戦略

### ⚠️ 段階的採用（フェーズ2以降）
5. ⚠️ 冗長アンカー（まず末尾のみ、失敗率5%超なら拡張）

### ❌ 却下・見送り
6. ❌ 自動オフラインモード（要件を満たさないため）
7. ❌ 行シグネチャ検索（過剰設計、RapidFuzzで代替可能）

---

## 次のステップ

要件定義が確定したので、フェーズ1の実装に進みます。

**推奨実装順序:**
1. 環境セットアップ（`.env`設定、依存パッケージインストール）
2. Whisperモデルの検証（3モデル比較）
3. LLM API連携の実装（3プロバイダー対応）
4. タグ分離とアライメント処理
5. SRT出力と統合テスト
